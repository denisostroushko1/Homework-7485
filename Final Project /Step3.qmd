---
title: "Simulation Project - Step 3 - Results"
format: pdf
execute: 
  echo: false 
  warning: false 
  message: false 
---

# Results 

```{r}
path = substr(getwd(), 
              1, 
              nchar(getwd()) - nchar("Final Project ")
              )
source(paste0(path, "/Master Packages.R"))

res.1 <- readRDS(
  paste0(
    getwd(), "/simulation results/result1.RDS")
)

res.2a <- readRDS(
  paste0(
    getwd(), "/simulation results/result2a.RDS")
)

res.2b <- readRDS(
  paste0(
    getwd(), "/simulation results/result2b.RDS")
)

res.2c <- readRDS(
  paste0(
    getwd(), "/simulation results/result2c.RDS")
)

res.3a <- readRDS(
  paste0(
    getwd(), "/simulation results/result3a.RDS")
)

res.3b <- readRDS(
  paste0(
    getwd(), "/simulation results/result3b.RDS")
)

res.3c <- readRDS(
  paste0(
    getwd(), "/simulation results/result3c.RDS")
)

res.4a <- readRDS(
  paste0(
    getwd(), "/simulation results/result4a.RDS")
)

res.4b <- readRDS(
  paste0(
    getwd(), "/simulation results/result4b.RDS")
)

res.5 <- readRDS(
  paste0(
    getwd(), "/simulation results/result5.RDS")
)

res.6 <- readRDS(
  paste0(
    getwd(), "/simulation results/result6.RDS")
)

all_results <- 
  rbind(res.6, 
        res.5, 
        res.4b, 
        res.4a, 
        res.3c, 
        res.3b,
        res.3a, 
        res.2c,
        res.2b,
        res.2a,
        res.1) %>% unique() %>% 
  filter(!(method %in% c("experience based", "pca - 80% of variance", "ttest"))) %>% 
  mutate(method = factor(method, 
                         levels = c("best case", setdiff(unique(method), "best case")))) %>% 
  arrange(n,m,s,method)%>% 
  mutate(ipw2_bias = ATE.true - ATE.ipw2, 
         pss_bias = ATE.true - ATE.pss, 
         p_important_var = s/m)
```

# Introduction 



```{r}
#| fig-height: 6 
#| fig-width: 8
all_results %>% 
  ggplot(aes(x = method, 
             fill = method, 
             y = SE.ipw2)) + 
  theme_minimal() + 
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5), 
        legend.position = "bottom") + 
  labs(x = "", 
       y = "Average Bootsrapped Standard Error", 
       color = "Variable Selection Method") + 
  guides(color = guide_legend(nrow = 2))
```

```{r}
#| label: fig-p-vars
#| fig-cap: "Relationship between % of true covariates and the IPW2 bootstrap standard error. Y-asix on the log sclae for more clear visualization"
#| fig-height: 6 
#| fig-width: 8
all_results %>% 
  ggplot(aes(x = p_important_var, 
             y = SE.ipw2, 
             color = method)) + 
  theme_minimal() + 
  geom_point() + 
  stat_smooth(method = "lm") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5), 
        legend.position = "bottom") + 
  scale_y_continuous(trans = "log") + 
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1)) + 
  labs(x = "% of Truly Imporatant Variables", 
       y = "Average Bootstrapped Standard Error") + 
  guides(color = guide_legend(nrow = 2))
  
```

```{r}
#| fig-height: 6 
#| fig-width: 8
all_results %>% 
  group_by(n, method) %>% 
  summarise(mean_se = mean(SE.ipw2, na.rm = T), 
            sd_low = quantile(SE.ipw2, 0.025, na.rm = T),
            sd_high = quantile(SE.ipw2, 0.975, na.rm = T)
            ) %>% 
  ggplot(aes(x = n, y = mean_se, group = method, color = method)) + 
    theme_minimal() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 0.5), 
          legend.position = "bottom") + 
    geom_point() + 
    geom_line() + 
    labs(x = "Sample size N", 
         y = "Average Bootstrapped Standard Error") + 
    guides(color = guide_legend(nrow = 2))

```

# Gaussian Linear Model for Factor Effects 

We fit a general regression model to interpret marginal effects of variable factors on the variance estimates using bootstrap. 
For the purpose of regression modeling, we transform the reponse, a bootstrap standard error of an estiamtor from each replication to the logarithmic scale. Due to our data generating mechanism, interpretation of point change in variance would not 
provide interpretable enough main effects. In contrast, log-transofrmation allows us to get effect of variable parameters 
in terms of percentage change, which allows us to compare variances of estimators that have varying magnitude. 

@tbl-coeff shows main effects of considered varying parameters on the log-bootstrap error. We consider interaction between 
variable selection method and the numnber of true covariates to evalaute how well each method does when the number of 
confounders that we need to capture varies. 

```{r}
#| label: tbl-coeff
#| tbl-cap: "Gaussian GLM for main effects on Log-Bootstrap Standard Error. \\ All coefficients and interval bounds are exponentiated. Predictors explain 81% of variation in log-transformed bootstrap standard errors of estimators."

model_1 = lm(log(SE.ipw2) ~ method + m + n + s + method:s, data = all_results) 

summary(model_1)$r.squared -> rsq


summary(
  model_1
      #family = gaussian(link = 'log'))
)$coefficients %>% 
  data.frame() %>% 
  mutate(
         CI_low = exp(Estimate - 1.96 * Std..Error), 
         CI_high = exp(Estimate + 1.96 * Std..Error), 
         Estimate = exp(Estimate)
         ) %>% 
  round(., 4) %>% 
  mutate(var = rownames(.)) %>% 
  
  select(var, Estimate, CI_low, CI_high)  %>% 
  mutate(var = case_when(var == "methodadaptive lasso" ~ "Adaptive Lasso", 
                         var == "methodexperience based (10 covariates)" ~ "Experience-Based (10 covariates)", 
                         var == "methodforward selection" ~ "Forward selection", 
                         var == "methodlasso" ~ "Lasso", 
                         
                         var == "methodadaptive lasso:s" ~ "Adaptive Lasso:s",
                         var == "methodexperience based (10 covariates):s" ~ "Experience-Based (10 covariates):s", 
                         var == "methodforward selection:s" ~ "Forward selection:s", 
                         var == "methodlasso:s" ~ "Lasso:s", 
                         T ~ var)) -> tabsum

rownames(tabsum) <- NULL

tabsum %>% 
  kable(digits = 4, 
        col.names = c("Model Term", "Exp. Estiamte", "Lower CI Bound", "Higher CI Bound"), 
        align = c('l', 'c', 'c', 'c'), 
        booktabs = T)
  

```

Best case scenario was used as a reference level for the variable selection methods. The variance of best case scenario method is then defined by the variance of residuals specified in the data generating mechanism. 
Each other method that is tasked with 
selecting best predictors under sampling uncertainty is compared to the best case scenario. Main effects for 
variable selection methods show that Lasso and Adaptive Lasso {causal variable selction method} perform about the same, 
with average bootsrap stanrd error being about 16% higher than the best case scenario. 

Purely data driven method of forward variable selection performs worse than all other methods. The nature of "Experience Based" method, which always selects 5 true and 5 random predictors, makes me think that a step wise forward variable selection method 
must have a ratio of false positive to true positive predictors that is less than 50%, which then leads to the higher degree 
of model misspecification, and therefore higher variance of the estiamtor. 

We consider parameter $s$, the number of true predictors for treatment and outcome, as well as its interaction with variable selection methods. As the number of true predictor, or true $confounders$, increases, we expect that the task of selecting true confounders through considered methods becomes harder. Therefore, we want to know how each method behaves as the number of 
counders increases. 

* Main effect of $s$ shows that for the best case scenario, an extra additional predictor resulted in about 5% increase of bootstrap standard error, after adjusting for other varying parameters. It also appears that this effect is stronger than other 
variable selection methods, as shown on @fig-p-vars. This means that even we are able to correctly specify the model and capture all true confoudners, more complicated data generating schemas with a larger number of truly important predictors still inheret a higher degree of variability. 

* For each other variable selection, the effect of an additional significant predictor increased the standard error of an 
estimator by about 3-3.5%. 

* It is interesting to note that the number of total covatiates present in the data set has no effect on the bootsrap standard error. 


```{r}
#| eval: false
all_results %>% 
  group_by(
    method, s
  ) %>% 
  summarise(
    mse = mean((ATE.ipw2 - ATE.true)^2)
  ) %>% 
  arrange(s, method)


```

