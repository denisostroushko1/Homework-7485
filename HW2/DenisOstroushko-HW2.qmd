---
title: "Denis Ostroushko - HW2"
format: 
  pdf:
    toc: false
execute: 
  echo: false
  warning: false
  message: false
---

```{r read packages }
total_nchar = nchar(getwd())
remove_nchar = nchar("HW1")
path = substr(getwd(), 1, total_nchar - remove_nchar)
source(paste0(path,"Master Packages.R"))
```

```{r read in data}
data1 <- load("OPT_Study_PUBH7485_8485_2023.Rdata")

# Notice that the result of this function is not assigned to an object name. When R calls load(), all of the R objects saved in the file are loaded into R. The names given to these objects when they were originally saved will be given to them when they are loaded. The command >  ls() can be used to print out all of the objects currently loaded into R.

# https://higgi13425.github.io/medicaldata/reference/opt.html

#     summary(data)

## imputation 

median_bw <- median(data$Birthweight, na.rm = T)
median_npp <- median(data$N.prev.preg, na.rm = T)

mode_race <- 
  names(
    (table(data$Race_ethnicity) %>% sort())[length(table(data$Race_ethnicity))]
    )

mode_tob <- 
  as.character(names(
    (table(data$Use.Tob) %>% sort())[length(table(data$Use.Tob))]
    ))

data[is.na(data$Race_ethnicity), ]$Race_ethnicity <- mode_race
data[is.na(data$Use.Tob), ]$Use.Tob <- mode_tob
data[is.na(data$N.prev.preg), ]$N.prev.preg <- median_npp
data[is.na(data$Birthweight), ]$Birthweight <- median_bw

```

# Introduction 

### Imputation 

Following instructions from *Homework 1*, we identify  Birthweight, N.prev.preg, 
Race_ethnicity, and Use.Tob as variables that are subject to imputation.. 

For the purpose of this problem, we need to impute categorical variables with 
mode values, and continuous variables with medians. 

Median Birth weight from observed values is `r median_bw`, median number of previous pregnancies is `r median_npp`. 

Most common value of Race/Ethnicity Variable is `r mode_race `, most common status of tobacoo usage is `r mode_tob`

### Study Objective

Like in Assignment 1, we consider indicator for pregnancies that ended before 37 weeks, `Preg.ended...37.wk`, and 
birth weights of newborns as outcomes. We will use IPW2 and Propensity Score Stratification methods to obtain average 
treatment effects. For pregnancy terms, we wish to test if proportion of pregnancies that ended before 37 weeks reduced 
for the treated sample. We also wish to test if the average birth weight of newborns was higher in the treatment group. 

### Study Sample Summary 

Outcome variable is treatment assignment. There are `r length(which(data$Group == "T"))` patients in the treatment group, 
which corresponds to the `r round(length(which(data$Group == "T"))/nrow(data), 4) * 100`% of the study population. 

```{r}
#| eval: false 
data %>% select(Group, Race_ethnicity, Public.Asstce,
                         Use.Tob, N.prev.preg, Live.PTB, 
                         BL.GE, BL..BOP, BL..PD.4, BL..CAL.3) %>% summary()
```

```{r}
#| include: false
#| results: hide
#| 
CreateTableOne(
  data = data %>% select(Group, `Preg.ended...37.wk`, Birthweight, Race_ethnicity, Public.Asstce,
                         Use.Tob, N.prev.preg, Live.PTB, 
                         BL.GE, BL..BOP, BL..PD.4, BL..CAL.3), 
  strata = "Group",
  vars = 
    setdiff(
      data %>% select(Group, `Preg.ended...37.wk`, Birthweight, Race_ethnicity, Public.Asstce,
                         Use.Tob, N.prev.preg, Live.PTB, 
                         BL.GE, BL..BOP, BL..PD.4, BL..CAL.3) %>% colnames(), 
      "Group"
    ), 
  factorVars = c("Race_ethnicity", "Public.Asstce", "Use.Tob", "Live.PTB"), 
  test = F
) -> raw_table_1 

table_1_for_printing <- print(raw_table_1, smd = T, showAllLevels = T)
  
```

```{r kable table 1 }
#| label: tbl-fig-1
#| tbl-cap: "Summary of Confoudnding Variables Between Treatment Groups" 

table_1_for_printing %>% 
  kable(
    booktabs = T, 
    longtable = T
  ) %>% 
  kable_styling(
    font_size = 8, 
    latex_options = c("striped", "HOLD_position")
  )

```

```{r save down SMD before weighting }

rownames(ExtractSmd(raw_table_1)) -> confounders 

ExtractSmd(raw_table_1) -> unweight_smd

```


@tbl-fig-1 shows that there are some covariates that are imbalanced between the two treatment groups. BL..CAL.3, BL.GE, 
Live.PTB, Race_ethnicity all have SMD greater than 0.1. 

### Model Specification 

In order to control for these confounding variables we will use a logistic regression model with no interactions and 
linear terms only. We specify the following model in order to obtain propensity score.

Let $A_i$ be a binary random variable, with 1 representing assignment to the treatment group.

Let $\pi_i = P(A_i = 1)$ be a  propensity score for $i^{th}$ subject. 

We obtain propensity scores $\pi_i$ by fitting the following model: 

```{r}
#| echo: true
propensity_score_model <- glm(
  
  I(data$Group == "T") %>% as.numeric() ~ 
    Race_ethnicity + Public.Asstce +
    Use.Tob + N.prev.preg + Live.PTB + 
    BL.GE + BL..BOP + BL..PD.4 + BL..CAL.3, 
  
  data = data, 
  family = "binomial"
)
    
data$propensity_scores = propensity_score_model$fitted.values

```

At this point I do not verify that the model fits the data reasonably well, for the purpose of this assignment I assume that 
this model is appropriate for propensity score estimation (which may or may not be true).

@fig-propensity-hist shows distribution of estimated propensity scores. It appears that there are no values beyond score of 
0.65. 

```{r}
#| label: fig-propensity-hist
#| fig-cap: "Distribution of Propensity Scores" 

ggplot(data = data, 
       aes(x = propensity_scores)) + geom_histogram(bins = 20, color = 'black', fill = 'grey') + 
  theme_classic() + 
  
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1), 
                     limits = c(0, 1)) + 
  
  labs(x = "Estiamted Propensity Scores", 
       y = "Count")
  
```

# Problem 1 

## Propensity Score Stratication 

First, we divide obtain propensity scores into 5 quintiles. We observe that the first and last quintiles are quite wide, 
due to the distribution of scores and shape of said distribution. 

```{r}

cut(data$propensity_scores, 
    breaks = c(0, 
               quantile(data$propensity_scores, p = c(0.2, 0.5, 0.6, 0.8)), 
               1)
    ) -> quint

data$quint = quint
```

@tbl-quint shows observed number of study subjects in each group after partitioning propensity scores. 

```{r }
#| label: tbl-quint
#| tbl-cap:  "Distribution of observations across Propensity Score Groups and Treatment Groups" 

table(data$quint, data$Group) %>% 
  kable(col.names = c("Controls", "Treatment"), 
        booktabs = T) 

```

@tbl-quint2 shows proportion of each class in a given partition of propensity scores. It appears, for the last two categories 
the balance of classes within quintiles shifts. 

```{r }
#| label: tbl-quint2
#| tbl-cap:  "Distribution of classes within each Propensity Score Group"  

data %>% 
  group_by(quint) %>% summarise(n = n()) %>% select(n) %>% unlist() -> quint_N

data <- data %>% select(-quint)

(table(quint, data$Group)/quint_N) %>% 
  kable(col.names = c("Controls", "Treatment"), 
        digits = 2, 
        booktabs = T) 

```

### Impact of Treatment on Pre-Term Pregnancy Rate 

We estimate ATE using \begin{equation}
    \hat{\delta} = \sum_{j=1}^5 (\overline{Y}_{1j} - \overline{Y}_{0j}) \frac{n_j}{n}
    \end{equation}

In R, we use the following steps: 

1. Obtain average proportion of pre-term pregnancies in each quintile in each treatment group

2. Take the difference within each quintile

3. Take a weighted sum of differences. Weigh differences using distribution of quintiles in the data. 

@tbl-preg-hat-delta shows statistics from the data that we need to estimate $\hat \delta$. 

```{r}
#| label: tbl-preg-hat-delta
#| tbl-cap: "Statistics for average treatment effect estimation" 
data %>% 
  mutate(quint = quint,
         preg_outcome = ifelse(`Preg.ended...37.wk` == "Yes", 1, 0)) %>% 
  group_by(quint, Group) %>% 
  summarise(
    n = n(), 
    p = mean(preg_outcome)
  ) -> t1 


cbind(
  t1 %>% filter(Group == "T") %>% 
    ungroup() %>% 
    select(quint, n, p) %>% 
    rename(n_trt = n, 
           p_trt = p), 
  t1 %>% filter(Group == "C") %>% 
    ungroup() %>% 
    select(n, p) %>% 
    rename(n_cnt = n, 
           p_cnt = p)
) %>% 
mutate(
  q_weight = (n_cnt + n_trt)/(sum(n_cnt) + sum(n_trt))
) -> f_delta_preg

f_delta_preg %>% 
  kable(
    booktabs = T, 
    col.names = c("Quintile", "N Treated", "% Pre-Term Pregnancies for Treated", 
                  "N Controls", "% Pre-Term Pregnancies for Controls", "Quintile Weight"), 
    digits = 2, 
    align = 'c'
  ) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position")) %>% 
  column_spec(c(3, 5), width = "2cm")

```

```{r}
sum((f_delta_preg$p_trt - f_delta_preg$p_cnt) * f_delta_preg$q_weight) -> hat_delta_preg
```

Using these statistics, we obtain the average treatment effect of `r round(hat_delta_preg, 2)`, implying that on average 
this program will reduce pre-term pregnancy rates by `r abs(round(hat_delta_preg, 3)*100)`%

**Boostrap comments** 

In order to obtain a standard error of this estimate we follow these steps 500 times: 

1. Resample data 

2. Fit propensity score model on the resampled data, obtain new propensity scores 

3. Obtain statistics required to estimate ATE, as shown in @tbl-preg-hat-delta

4. Store ATE and return to step (1)

```{r propensity score strat - pre term prog - se estiamtion bootsrap}
#| eval: false

res <- 
  data.frame(
    i = c(1:500), 
    ATE = NA,
    ATE_ipw = NA
  )
set.seed(7892347)

for(i in 1:500){
  
  if(i %% 50 == 0){print(paste0(i, " of ", 500))}
  
  iter_data = data[sample(1:nrow(data), replace = T), ]
  
  #estimate new propensity score model 
  iter_propensity_score_model <- glm(
    I(iter_data$Group == "T") %>% as.numeric() ~ 
      Race_ethnicity + Public.Asstce +
      Use.Tob + N.prev.preg + Live.PTB + 
      BL.GE + BL..BOP + BL..PD.4 + BL..CAL.3, 
    
    data = iter_data, 
    family = "binomial"
  )
      
  iter_data$propensity_scores = iter_propensity_score_model$fitted.values
  
  # cut the data into propensity scores 
  cut(iter_data$propensity_scores, 
      breaks = c(0, 
                 quantile(iter_data$propensity_scores, p = c(0.2, 0.5, 0.6, 0.8)), 
                 1)
      ) -> quint
  
  iter_data$quint = quint
  
  # obtain table for estimation 
  iter_data %>% 
    mutate(quint = quint,
           preg_outcome = ifelse(`Preg.ended...37.wk` == "Yes", 1, 0)) %>% 
    group_by(quint, Group) %>% 
    summarise(
      n = n(), 
      p = mean(preg_outcome)
    ) -> t1 
  
  
  cbind(
    t1 %>% filter(Group == "T") %>% 
      ungroup() %>% 
      select(quint, n, p) %>% 
      rename(n_trt = n, 
             p_trt = p), 
    t1 %>% filter(Group == "C") %>% 
      ungroup() %>% 
      select(n, p) %>% 
      rename(n_cnt = n, 
             p_cnt = p)
  ) %>% 
  mutate(
    q_weight = (n_cnt + n_trt)/(sum(n_cnt) + sum(n_trt))
  ) -> iter_f_delta_preg
  
  #estimate effect and store results
  sum((iter_f_delta_preg$p_trt - iter_f_delta_preg$p_cnt) * iter_f_delta_preg$q_weight) -> iter_hat_delta_preg
  
  res$ATE[i] = iter_hat_delta_preg

  ## Calculate IPW2 effect as well 
  
  iter_w_trt = 
    ifelse(iter_data$Group == "T", 1, 0)/ # vector of outcomes 0/1
    iter_propensity_score_model$fitted.values # vector of corresponding propensity scores 
  
  iter_w_cnt = 
    (1 - ifelse(iter_data$Group == "C", 1, 0))/ # vector that identifies '0's as '1's
    (1-iter_propensity_score_model$fitted.values)
  
  weighted.mean(ifelse(iter_data$Preg.ended...37.wk == "Yes", 1, 0), iter_w_trt) - 
    weighted.mean(ifelse(iter_data$Preg.ended...37.wk == "Yes", 1, 0), iter_w_cnt) -> iter_preg_ipw2_ATE
  
  res$ATE_ipw[i] = iter_preg_ipw2_ATE
  }

summary(res$ATE)
summary(res$ATE_ipw)

ggplot(data = res, 
       aes(x = ATE)) + geom_histogram(binwidth = 0.01, color = "black",  fill = "grey") + theme_classic()

ggplot(data = res, 
       aes(x = ATE_ipw)) + geom_histogram(binwidth = 0.01, color = "black",  fill = "grey") + theme_classic()

write_csv(res, "prop_strat_pre_term_preg_ATE_bootsrap.csv")
```

**Conclusion**

```{r}
pre_term_boot_se <- read_csv("prop_strat_pre_term_preg_ATE_bootsrap.csv")
se = sd(pre_term_boot_se$ATE)
```

* Average (causal) treatment effect of program participation on pre-term pregnancy rates is `r round(hat_delta_preg, 2)`

* Bootstrap estimate of standard error for this estimate is `r round(se, 2)`

* 95% normal confidence interval is (`r round(hat_delta_preg - 1.96 * se, 2)`, `r round(hat_delta_preg + 1.96 * se, 2)`)

### Impact of Treatment on Average Birth Weight 

Using the same steps we can obtain ATE on newborn birth weights. I will skip over the details and will provide a 
table with statistics required for the estimation process. In order to estimate ATE, we use the same propensity score 
model and corresponding propensity scores. 

@tbl-bw-hat-delta shows intermediate statistics obtained in the estimation process. 

```{r}
#| label: tbl-bw-hat-delta
#| tbl-cap: "Statistics for average treatment effect estimation" 
data %>% 
  mutate(quint = quint) %>% 
  group_by(quint, Group) %>% 
  summarise(
    n = n(), 
    p = mean(Birthweight)
  ) -> t1 


cbind(
  t1 %>% filter(Group == "T") %>% 
    ungroup() %>% 
    select(quint, n, p) %>% 
    rename(n_trt = n, 
           p_trt = p), 
  t1 %>% filter(Group == "C") %>% 
    ungroup() %>% 
    select(n, p) %>% 
    rename(n_cnt = n, 
           p_cnt = p)
) %>% 
mutate(
  q_weight = (n_cnt + n_trt)/(sum(n_cnt) + sum(n_trt))
) -> f_delta_preg

f_delta_preg %>% 
  kable(
    booktabs = T, 
    col.names = c("Quintile", "N Treated", "Averege Birthweights for Treated", 
                  "N Controls", "Averege Birthweights for Controls", "Quintile Weight"), 
    digits = 2, 
    align = 'c'
  ) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position")) %>% 
  column_spec(c(3, 5), width = "2cm")

```

```{r}
sum((f_delta_preg$p_trt - f_delta_preg$p_cnt) * f_delta_preg$q_weight) -> hat_delta_bw
```

```{r propensity score strat - average brth weight - se estiamtion bootsrap}
#| eval: false
#| results: hide
res <- 
  data.frame(
    i = c(1:500), 
    ATE = NA, 
    ATE_ipw = NA
  )
set.seed(7892347)

for(i in 1:500){
  
  if(i %% 50 == 0){print(paste0(i, " of ", 500))}
  
  iter_data = data[sample(1:nrow(data), replace = T), ]
  
  #estimate new propensity score model 
  iter_propensity_score_model <- glm(
    I(iter_data$Group == "T") %>% as.numeric() ~ 
      Race_ethnicity + Public.Asstce +
      Use.Tob + N.prev.preg + Live.PTB + 
      BL.GE + BL..BOP + BL..PD.4 + BL..CAL.3, 
    
    data = iter_data, 
    family = "binomial"
  )
      
  iter_data$propensity_scores = iter_propensity_score_model$fitted.values
  
  # cut the data into propensity scores 
  cut(iter_data$propensity_scores, 
      breaks = c(0, 
                 quantile(iter_data$propensity_scores, p = c(0.2, 0.5, 0.6, 0.8)), 
                 1)
      ) -> quint
  
  iter_data$quint = quint
  
  # obtain table for estimation 
  iter_data %>% 
    mutate(quint = quint) %>% 
    group_by(quint, Group) %>% 
    summarise(
      n = n(), 
      p = mean(Birthweight)
    ) -> t1 
  
  
  cbind(
    t1 %>% filter(Group == "T") %>% 
      ungroup() %>% 
      select(quint, n, p) %>% 
      rename(n_trt = n, 
             p_trt = p), 
    t1 %>% filter(Group == "C") %>% 
      ungroup() %>% 
      select(n, p) %>% 
      rename(n_cnt = n, 
             p_cnt = p)
  ) %>% 
  mutate(
    q_weight = (n_cnt + n_trt)/(sum(n_cnt) + sum(n_trt))
  ) -> iter_f_delta_preg
  
  #estimate effect and store results
  sum((iter_f_delta_preg$p_trt - iter_f_delta_preg$p_cnt) * iter_f_delta_preg$q_weight) -> iter_hat_delta_preg
  
  res$ATE[i] = iter_hat_delta_preg
  
  
  ## Calculate IPW2 effect as well 
  
  iter_w_trt = 
    ifelse(iter_data$Group == "T", 1, 0)/ # vector of outcomes 0/1
    iter_propensity_score_model$fitted.values # vector of corresponding propensity scores 
  
  iter_w_cnt = 
    (1 - ifelse(iter_data$Group == "T", 1, 0))/ # vector that identifies '0's as '1's
    (1-iter_propensity_score_model$fitted.values)
  
  weighted.mean(iter_data$Birthweight, iter_w_trt) - 
    weighted.mean(iter_data$Birthweight, iter_w_cnt) -> iter_preg_ipw2_ATE
  
  res$ATE_ipw[i] = iter_preg_ipw2_ATE
}

summary(res$ATE)
summary(res$ATE_ipw)

ggplot(data = res, 
       aes(x = ATE)) + geom_histogram(binwidth = 25, color = "black",  fill = "grey") + theme_classic()

ggplot(data = res, 
       aes(ATE_ipw)) + geom_histogram(binwidth = 25, color = "black",  fill = "grey") + theme_classic()


write_csv(res, "prop_strat_birthweight_ATE_bootsrap.csv")
```


**Conclusion**

```{r}
birthweight_se <- read_csv("prop_strat_birthweight_ATE_bootsrap.csv")
se = sd(birthweight_se$ATE)
```

* Average (causal) treatment effect of program participation on average birth weights `r round(hat_delta_bw, 2)`

* Bootstrap estimate of standard error for this estimate is `r round(se, 2)`

* 95% normal confidence interval is (`r round(hat_delta_bw - 1.96 * se, 2)`, `r round(hat_delta_bw + 1.96 * se, 2)`)

## Inverse Probability Weighting 

In this section we will use IPW2 weighting, with propensity scores we used for the previous estimation method. 

### Impact of Treatment on Pre-Term Pregnancy Rate 

Using propensity scores, we obtain weights for each subject in the study. 
Distribution of weights is shown on @fig-weights-preg. 


```{r}
#| echo: true
w_trt = 
  ifelse(data$Group == "T", 1, 0)/ # vector of outcomes 0/1
  propensity_score_model$fitted.values # vector of corresponding propensity scores 

w_cnt = 
  (1 - ifelse(data$Group == "T", 1, 0))/ # vector that identifies '0's as '1's
  (1-propensity_score_model$fitted.values)
```



```{r}
#| label: fig-weights-preg
#| fig-cap: "Distribution of Weights for Controls and Treated Using Inverse Propensity Scores" 
#| fig-width: 10
#| fig-height: 6
ggplot(data = data.frame(w = w_trt[w_trt!= 0]), 
       aes(x = w)) + 
  geom_histogram(binwidth = 0.5, color = "black",  fill = "grey") + 
  theme_classic() + 
  labs(x = "Weights", 
       y = "Count") + 
  ggtitle("Weight Distribution for Treated Group") -> p1 

ggplot(data = data.frame(w = w_cnt[w_cnt!= 0]), 
       aes(x = w)) + 
  geom_histogram(binwidth = 0.2, color = "black",  fill = "grey") + 
  theme_classic() + 
  labs(x = "Weights", 
       y = "Count") + 
  ggtitle("Weight Distribution for Control Group") -> p2

grid.arrange(p1, p2, nrow = 1)
```


Using IPW2 weighting approach: 

```{r ipw effect for comparison preg}
#| eval: false 

mean(ifelse(data$Preg.ended...37.wk == "Yes", 1, 0) * w_trt) - 
  mean(ifelse(data$Preg.ended...37.wk == "Yes", 1, 0) * w_cnt)
```

```{r}
#| echo: true
weighted.mean(ifelse(data$Preg.ended...37.wk == "Yes", 1, 0), w_trt) - 
  weighted.mean(ifelse(data$Preg.ended...37.wk == "Yes", 1, 0), w_cnt) -> preg_ipw2_ATE

```

We employ the same bootstrap approach as described before to obtain standard error for this approach. 

Bootstrapped ATEs were calculated in the same loop as Propensity Score Stratification ATEs, which means 
bootstrapped models and 
propensity scores were reused for the two estimators within each bootstrap iteration. 

**Conclusion**

* IPW2 ATE estimate for reduction in pre-term pregnancy rates is `r round(preg_ipw2_ATE, 4)`

* Bootstrapped standard error is `r round(sd(pre_term_boot_se$ATE_ipw), 4)`

* 95% Normal Confidence Interval is (`r round(preg_ipw2_ATE - sd(pre_term_boot_se$ATE_ipw) * 1.96, 2)`, `r round(preg_ipw2_ATE + sd(pre_term_boot_se$ATE_ipw) * 1.96, 2)`)

### Impact of Treatment on Average Birthweight

In this section we reuse inverse weight shown on @fig-weights-preg. Using the same steps, we obtain IPW2 estiamte for 
the ATE on average birth weights. 

IPW2 estimation approach: 

```{r ipw effect for comparison bw}
#| eval: false 

mean(data$Birthweight * w_trt) - 
  mean(data$Birthweight * w_cnt)
```

```{r}
#| echo: true
weighted.mean(data$Birthweight, w_trt) - 
  weighted.mean(data$Birthweight, w_cnt) -> bw_ipw2_ATE

```

**Conclusion**

* IPW2 ATE estimate for increase in average birth weight of newborns `r round(bw_ipw2_ATE, 4)`

* Bootstrapped standard error is `r round(sd(birthweight_se$ATE_ipw), 2)`

* 95% Normal Confidence Interval is (`r round(bw_ipw2_ATE - sd(birthweight_se$ATE_ipw) * 1.96, 2)`, 
`r round(bw_ipw2_ATE + sd(birthweight_se$ATE_ipw) * 1.96, 2)`)

## Final Results Problem 1

Putting all work together: 

 - 1. We have fit a logistic regression to estimate each participants probability of being in the treatment group 
      * We assumed the model is correct, fits the data reasonably well (which I did not verify) 
      * We assume positivity, and verify that obtained propensity scores are greater than 0
 
 - 2. Using obtained propensity scores, we identified 5 strata of propensity scores based on quintiles 
 
 - 3. For each outcome, newborn birth weights and events of pre-term pregnancies, we found ATE using propensity score 
      stratification 
      
  - 4. For each outcome we found ATE using IPW2 
  
  - 5. Using bootstrap we found distribution of ATEs for each method for each outcome, using these distributions we 
      found standard errors for each ATE estimate, and corresponding 95% normal confidence intervals 
      
Table @tbl-part-1-summary-p shows estimated quantities for treatment effect on pre-term pregnancy rates. 

```{r part 1 summary table p}
#| label: tbl-part-1-summary-p
#| tbl-cap: "Final Estimates for Pre-Term Pregnancy Reduction ATE"
#| 
data.frame(
  Type = c("PSS", "IPW2"), 
  Est = c(preg_ipw2_ATE, hat_delta_preg), 
  se = c(sd(pre_term_boot_se$ATE), sd(pre_term_boot_se$ATE_ipw))
) %>% 
  mutate(low = Est - 1.96 * se, 
         high = Est + 1.96 * se) -> preg_outs 

preg_outs %>% 
  kable(booktabs = T, 
        align = 'c', 
        digits = 2, 
        col.names = c("Method", "ATE", "Estimate SE", "95% C.I. Lower Bound", "95% C.I. Upper Bound")) 
```

Table @tbl-part-1-summary-bw shows estimated quantities for treatment effect on average birth weights. 

```{r part 1 summary table bw}
#| label: tbl-part-1-summary-bw
#| tbl-cap: "Final Estimates for Pre-Term Pregnancy Reduction ATE"
#| 
data.frame(
  Type = c("PSS", "IPW2"), 
  Est = c(hat_delta_bw, bw_ipw2_ATE), 
  se = c(sd(birthweight_se$ATE), sd(birthweight_se$ATE_ipw))
) %>% 
  mutate(low = Est - 1.96 * se, 
         high = Est + 1.96 * se) -> bw_outs

bw_outs %>% 
  kable(booktabs = T, 
        align = 'c', 
        digits = 2, 
        col.names = c("Method", "ATE", "Estimate SE", "95% C.I. Lower Bound", "95% C.I. Upper Bound")) %>% 
  kable_styling(latex_options = c("HOLD_position", "striped") )

```

# Problem 2

```{r}
read_csv(paste0(path, "HW1/birthweight ate bootsrap.csv")) ->  bw_regression_ate
read_csv(paste0(path, "HW1/pregnancy ate bootsrap.csv")) -> preg_regression_ate 
```

Recall that in HW1 we obtained ATE for the two outcomes using regression adjustment methods and comparing average outcomes 
when everyone in the population would be treated vs scenarios where no one would be treated. 

I will refer to these ATEs as Regression ATE when adding them to the plot. 

@fig-ates-preg compares three methods of obtaining ATE in terms of point estimate and 95% confidence intervals. 

@fig-ates-bw compares three methods of obtaining ATE in terms of point estimate and 95% confidence intervals. 

**Pre-Term pregnancy results** 

@fig-ates-preg shows that IPW2 method of estimation of causal effect produces an estimate with the lowest variance. 
Regression Adjustment and Propensity Score Stratification methods produce very similar estimates between the two methods.

Point estimates are pretty similar between the three methods. 

We know that the common perception is that modeling treatment allocation can be 'easier' than modeling the outcome. 

Therefore, it may be the case that a simple linear model with no interactions or higher order terms is more appropriate to 
model the treatment allocation. 

Also, it is likely that IPW2 method can handle outliers or extreme values better, and the effect of these values is not 
as strong within the bootstrap replications. 

However, the fact the IPW2 disagrees with a non parametric methods (PSS) and a regression based approach makes me think that 
we specified the models and omitted either important interaction terms when modeling propensity scores, or we 
omitted some potentially important covariates/confounders. 

**Birth weight results**

@fig-ates-bw shows that all three estimates have the same point estimates and same variance, as expressed by their confidence 
intervals. It appears that the data we have is not sensitive to estimation method. 

Agreement of the three methods in terms of point estimates and variance estimates makes me more convinced that we made 
the rihgt choices when it came to model specification for both treatment selection and outcome modeling. 

```{r}
#| label: fig-ates-preg
#| fig-cap: "95% Intervals that capture a red line imply that the estimate is not statistically different from zero"
#| 
preg_outs <- 
  rbind(preg_outs, 
        data.frame(
          Type = "Regression", 
          Est = mean(preg_regression_ate$ate), 
          se = sd(preg_regression_ate$ate)
        ) %>% 
          mutate(
            low = Est - 1.96 * se, 
            high = Est + 1.96 * se 
          )
        )

ggplot(data = preg_outs, 
       aes(x =  Type, y =  Est)) + 
  geom_point(size = 2) + 
  geom_errorbar(aes(ymin = low, ymax = high), width = 0.25) + 
  theme_classic() + 
  
  theme(
    title = element_text(size = 8)
  ) + 
  
  
  geom_hline(yintercept = 0, linetype = "dashed", size = 1, color = "red") + 
  
  xlab("Estimation Method") + 
  ylab("Estiamte with 95% Confidence Interval") + 
  
  ggtitle("Comaprison of Three Estiamtion Methods on Average \n Treatment Effect for Pre-Term Pregnancy Reduction Rates")

```

```{r}
#| label: fig-ates-bw
#| fig-cap: "95% Intervals that capture a red line imply that the estimate is not statistically different from zero"
#| 
bw_outs <- 
  rbind(bw_outs, 
        data.frame(
          Type = "Regression", 
          Est = mean(bw_regression_ate$ate), 
          se = sd(bw_regression_ate$ate)
        ) %>% 
          mutate(
            low = Est - 1.96 * se, 
            high = Est + 1.96 * se 
          )
        )

ggplot(data = bw_outs, 
       aes(x =  Type, y =  Est)) + 
  geom_point(size = 2) + 
  geom_errorbar(aes(ymin = low, ymax = high), width = 0.25) + 
  theme_classic() + 
  
  theme(
    title = element_text(size = 8)
  ) + 
  
  geom_hline(yintercept = 0, linetype = "dashed", size = 1, color = "red") + 
  
  xlab("Estimation Method") + 
  ylab("Estiamte with 95% Confidence Interval") + 
  
  ggtitle("Comaprison of Three Estiamtion Methods on Average \n Treatment Effect for Average Birthweights of Newborns")

```
